#!/usr/bin/env python3
"""
VTTech Full Data Sync Crawler
L·∫•y to√†n b·ªô d·ªØ li·ªáu t·ª´ h·ªá th·ªëng VTTech TMTaza

Author: Auto-generated
Date: 2025-12-24

Features:
- L·∫•y t·∫•t c·∫£ master data (branches, services, employees, users, etc.)
- L·∫•y d·ªØ li·ªáu kh√°ch h√†ng v·ªõi ƒë·∫ßy ƒë·ªß tr∆∞·ªùng
- L·∫•y l·ªãch h·∫πn (appointments)
- L·∫•y doanh thu (revenue)
- L·∫•y d·ªØ li·ªáu ƒëi·ªÅu tr·ªã (treatments) 
- L·∫•y kho h√†ng (inventory)
- H·ªó tr·ª£ pagination cho d·ªØ li·ªáu l·ªõn
- L∆∞u v√†o JSON v√† database

Usage:
    python3 full_sync_crawler.py                    # Sync t·∫•t c·∫£
    python3 full_sync_crawler.py --master-only      # Ch·ªâ master data  
    python3 full_sync_crawler.py --daily            # D·ªØ li·ªáu h√†ng ng√†y
    python3 full_sync_crawler.py --date 2025-12-01  # Ng√†y c·ª• th·ªÉ
    python3 full_sync_crawler.py --date-range 2025-12-01 2025-12-24  # Kho·∫£ng ng√†y
"""

import requests
import json
import base64
import zlib
import re
import os
import sys
import argparse
import logging
import time
from datetime import datetime, timedelta
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from typing import Optional, Dict, List, Any

# ============== CONFIG ==============
BASE_URL = "https://tmtaza.vttechsolution.com"
USERNAME = "ittest123"
PASSWORD = "ittest123"

# Th∆∞ m·ª•c output
BASE_DIR = Path(__file__).parent
SYNC_DIR = BASE_DIR / "data_sync"
LOG_DIR = BASE_DIR / "logs"

# T·∫°o th∆∞ m·ª•c
SYNC_DIR.mkdir(exist_ok=True)
LOG_DIR.mkdir(exist_ok=True)
(SYNC_DIR / "master").mkdir(exist_ok=True)
(SYNC_DIR / "customers").mkdir(exist_ok=True)
(SYNC_DIR / "appointments").mkdir(exist_ok=True)
(SYNC_DIR / "revenue").mkdir(exist_ok=True)
(SYNC_DIR / "treatments").mkdir(exist_ok=True)
(SYNC_DIR / "inventory").mkdir(exist_ok=True)
(SYNC_DIR / "services").mkdir(exist_ok=True)
(SYNC_DIR / "employees").mkdir(exist_ok=True)

# ============== LOGGING ==============
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(LOG_DIR / f"full_sync_{datetime.now().strftime('%Y%m%d')}.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


# ============== CRAWLER CLASS ==============
class VTTechFullSyncCrawler:
    """
    Crawler to√†n di·ªán cho h·ªá th·ªëng VTTech TMTaza
    """
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        self.token = None
        self.xsrf_tokens = {}  # Cache XSRF tokens cho t·ª´ng page
        self.branches = []
        self.stats = {
            'total_records': 0,
            'endpoints_called': 0,
            'errors': 0,
            'start_time': None
        }
    
    def decompress(self, data: str) -> Any:
        """Gi·∫£i n√©n response base64+gzip"""
        try:
            decoded = base64.b64decode(data)
            decompressed = zlib.decompress(decoded, 16 + zlib.MAX_WBITS)
            return json.loads(decompressed.decode('utf-8'))
        except:
            try:
                return json.loads(data)
            except:
                return data
    
    def login(self) -> bool:
        """ƒêƒÉng nh·∫≠p v√† l·∫•y token"""
        logger.info("üîê ƒêang ƒëƒÉng nh·∫≠p...")
        try:
            resp = self.session.post(
                f"{BASE_URL}/api/Author/Login",
                json={
                    "username": USERNAME,
                    "password": PASSWORD,
                    "passwordcrypt": "",
                    "from": "",
                    "sso": "",
                    "ssotoken": ""
                },
                timeout=30
            )
            data = resp.json()
            
            if data.get("Session"):
                self.token = data["Session"]
                self.session.cookies.set("WebToken", self.token)
                logger.info(f"‚úÖ ƒêƒÉng nh·∫≠p th√†nh c√¥ng: {data.get('FullName')} (ID: {data.get('ID')})")
                return True
            else:
                logger.error(f"‚ùå ƒêƒÉng nh·∫≠p th·∫•t b·∫°i: {data.get('RESULT')}")
                return False
        except Exception as e:
            logger.error(f"‚ùå L·ªói ƒëƒÉng nh·∫≠p: {e}")
            return False
    
    def init_page(self, page_url: str) -> bool:
        """L·∫•y XSRF token t·ª´ trang"""
        if page_url in self.xsrf_tokens:
            return True
            
        try:
            resp = self.session.get(f"{BASE_URL}{page_url}", timeout=30)
            if resp.status_code == 200:
                match = re.search(r'name=__RequestVerificationToken[^>]*value=([^\s/>]+)', resp.text)
                if match:
                    self.xsrf_tokens[page_url] = match.group(1)
                    return True
        except Exception as e:
            logger.error(f"‚ùå L·ªói init_page {page_url}: {e}")
        return False
    
    def call_handler(self, page_url: str, handler: str, data: Dict, retry: int = 3) -> Any:
        """G·ªçi handler v·ªõi XSRF token"""
        for attempt in range(retry):
            try:
                if not self.init_page(page_url):
                    continue
                    
                resp = self.session.post(
                    f"{BASE_URL}{page_url}?handler={handler}",
                    data=data,
                    headers={
                        'Content-Type': 'application/x-www-form-urlencoded',
                        'X-Requested-With': 'XMLHttpRequest',
                        'XSRF-TOKEN': self.xsrf_tokens.get(page_url, ''),
                        'Accept': '*/*',
                        'Origin': BASE_URL,
                        'Referer': f'{BASE_URL}{page_url}'
                    },
                    timeout=120
                )
                
                self.stats['endpoints_called'] += 1
                
                if resp.status_code == 200 and resp.content:
                    return self.decompress(resp.text)
                    
            except Exception as e:
                if attempt < retry - 1:
                    time.sleep(1)
                    continue
                logger.error(f"‚ùå L·ªói call_handler {page_url}?handler={handler}: {e}")
                self.stats['errors'] += 1
        return None
    
    def call_api(self, endpoint: str, data: Dict = None, retry: int = 3) -> Any:
        """G·ªçi API tr·ª±c ti·∫øp"""
        for attempt in range(retry):
            try:
                resp = self.session.post(
                    f"{BASE_URL}{endpoint}",
                    json=data or {},
                    headers={
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {self.token}"
                    },
                    timeout=120
                )
                
                self.stats['endpoints_called'] += 1
                
                if resp.status_code == 200 and resp.content:
                    return self.decompress(resp.text)
                    
            except Exception as e:
                if attempt < retry - 1:
                    time.sleep(1)
                    continue
                logger.error(f"‚ùå L·ªói call_api {endpoint}: {e}")
                self.stats['errors'] += 1
        return None
    
    def save_json(self, data: Any, filename: str, subdir: str = None) -> str:
        """L∆∞u d·ªØ li·ªáu ra file JSON"""
        if subdir:
            output_dir = SYNC_DIR / subdir
            output_dir.mkdir(exist_ok=True)
        else:
            output_dir = SYNC_DIR
        
        filepath = output_dir / f"{filename}.json"
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        logger.info(f"üíæ Saved: {filepath}")
        return str(filepath)

    # ==========================================
    # MASTER DATA SYNC
    # ==========================================
    
    def sync_session_data(self) -> Dict:
        """L·∫•y t·∫•t c·∫£ d·ªØ li·ªáu t·ª´ SessionData API"""
        logger.info("\nüì¶ ƒêang sync Session Data (Master)...")
        
        result = self.call_api("/api/Home/SessionData", {})
        if not result:
            logger.error("Kh√¥ng l·∫•y ƒë∆∞·ª£c SessionData")
            return {}
        
        # Mapping ƒë·∫ßy ƒë·ªß c√°c b·∫£ng
        table_mapping = {
            "Table": {
                "name": "branches",
                "description": "Chi nh√°nh",
                "fields": ["ID", "Name", "ShortName", "IP"]
            },
            "Table1": {
                "name": "teeth_data",
                "description": "D·ªØ li·ªáu rƒÉng (Dental)",
                "fields": ["ID", "Name", "Code", "Position"]
            },
            "Table2": {
                "name": "services",
                "description": "D·ªãch v·ª•",
                "fields": ["ID", "Name", "Code", "Color", "Type", "State", "Image", "Price", "GroupID"]
            },
            "Table3": {
                "name": "service_groups",
                "description": "Nh√≥m d·ªãch v·ª•",
                "fields": ["ID", "Name", "Color", "ParentID"]
            },
            "Table4": {
                "name": "employees",
                "description": "Nh√¢n vi√™n",
                "fields": ["ID", "Name", "Avatar", "GroupID", "State", "IsDoctor", "IsAssistant", 
                          "IsCSKH", "IsCashier", "IsLabo", "IsTech", "IsMarketing", "IsConsult"]
            },
            "Table5": {
                "name": "users",
                "description": "User accounts",
                "fields": ["ID", "Name", "Avatar", "RoleID", "EmployeeName", "EmployeeID"]
            },
            "Table6": {
                "name": "cities",
                "description": "T·ªânh/Th√†nh ph·ªë",
                "fields": ["ID", "Name", "Code"]
            },
            "Table7": {
                "name": "districts",
                "description": "Qu·∫≠n/Huy·ªán",
                "fields": ["ID", "Name", "CityID"]
            },
            "Table8": {
                "name": "countries",
                "description": "Qu·ªëc gia",
                "fields": ["ID", "Name", "Icon", "Code"]
            },
            "Table9": {
                "name": "wards",
                "description": "Ph∆∞·ªùng/X√£",
                "fields": ["ID", "Name", "DistrictID"]
            },
            "Table10": {
                "name": "customer_sources",
                "description": "Ngu·ªìn kh√°ch h√†ng",
                "fields": ["ID", "Name", "SPID", "ParentID"]
            }
        }
        
        today = datetime.now().strftime("%Y%m%d")
        saved_data = {}
        
        for table_key, info in table_mapping.items():
            if table_key in result:
                data = result[table_key]
                count = len(data)
                
                # L∆∞u file
                self.save_json(data, f"{info['name']}_{today}", "master")
                
                saved_data[info['name']] = {
                    "count": count,
                    "description": info['description'],
                    "fields": info['fields']
                }
                
                self.stats['total_records'] += count
                logger.info(f"  ‚úÖ {info['name']}: {count} records - {info['description']}")
                
                # Cache branches cho sau
                if info['name'] == 'branches':
                    self.branches = data
        
        # L∆∞u summary
        self.save_json({
            "sync_date": today,
            "tables": saved_data,
            "total_records": sum(t['count'] for t in saved_data.values())
        }, f"master_summary_{today}", "master")
        
        return saved_data
    
    def sync_branches_full(self) -> Dict:
        """L·∫•y th√¥ng tin chi nh√°nh ƒë·∫ßy ƒë·ªß (bao g·ªìm Membership, Status)"""
        logger.info("\nüè¢ ƒêang sync chi nh√°nh v·ªõi th√¥ng tin ƒë·∫ßy ƒë·ªß...")
        
        result = self.call_handler("/Customer/ListCustomer/", "Initialize", {})
        if result:
            today = datetime.now().strftime("%Y%m%d")
            
            branches = result.get('Branch', [])
            memberships = result.get('Membership', [])
            
            self.save_json(result, f"branches_full_{today}", "master")
            self.save_json(branches, f"branches_list_{today}", "master")
            self.save_json(memberships, f"memberships_{today}", "master")
            
            logger.info(f"  ‚úÖ Branches: {len(branches)}")
            logger.info(f"  ‚úÖ Memberships: {len(memberships)}")
            
            # Cache branches
            if branches:
                self.branches = branches
            
            return result
        return {}
    
    # ==========================================
    # CUSTOMER DATA SYNC
    # ==========================================
    
    def sync_customers(self, date_from: str, date_to: str, branch_id: int = 0, 
                       page_size: int = 500, max_pages: int = 100) -> List[Dict]:
        """L·∫•y danh s√°ch kh√°ch h√†ng v·ªõi pagination"""
        logger.info(f"\nüë• ƒêang sync kh√°ch h√†ng t·ª´ {date_from} ƒë·∫øn {date_to}...")
        
        all_customers = []
        start = 0
        page = 1
        
        while page <= max_pages:
            customers = self.call_handler(
                "/Customer/ListCustomer/",
                "LoadData",
                {
                    'dateFrom': f"{date_from} 00:00:00",
                    'dateTo': f"{date_to} 23:59:59",
                    'branchID': branch_id,
                    'start': start,
                    'length': page_size
                }
            )
            
            if not customers or not isinstance(customers, list) or len(customers) == 0:
                break
            
            all_customers.extend(customers)
            logger.info(f"  üìÑ Page {page}: {len(customers)} customers (Total: {len(all_customers)})")
            
            if len(customers) < page_size:
                break
            
            start += page_size
            page += 1
            time.sleep(0.5)  # Rate limiting
        
        if all_customers:
            today = datetime.now().strftime("%Y%m%d")
            self.save_json(all_customers, f"customers_{today}", "customers")
            self.stats['total_records'] += len(all_customers)
            logger.info(f"  ‚úÖ T·ªïng kh√°ch h√†ng: {len(all_customers)}")
        
        return all_customers
    
    def sync_customer_totals(self, date_from: str, date_to: str) -> List[Dict]:
        """L·∫•y t·ªïng h·ª£p doanh thu theo chi nh√°nh"""
        logger.info(f"\nüìä ƒêang sync t·ªïng h·ª£p doanh thu t·ª´ {date_from} ƒë·∫øn {date_to}...")
        
        if not self.branches:
            self.sync_branches_full()
        
        all_totals = []
        
        for branch in self.branches:
            result = self.call_handler(
                "/Customer/ListCustomer/",
                "LoadDataTotal",
                {
                    'dateFrom': f"{date_from} 00:00:00",
                    'dateTo': f"{date_to} 23:59:59",
                    'branchID': branch['ID']
                }
            )
            
            if result and isinstance(result, list):
                for item in result:
                    item['BranchID'] = branch['ID']
                    item['BranchName'] = branch['Name']
                    item['DateFrom'] = date_from
                    item['DateTo'] = date_to
                all_totals.extend(result)
                
                paid = result[0].get('Paid', 0) if result else 0
                logger.info(f"  ‚úÖ {branch['Name']}: {paid:,.0f} VND")
            
            time.sleep(0.3)
        
        if all_totals:
            today = datetime.now().strftime("%Y%m%d")
            self.save_json(all_totals, f"revenue_by_branch_{today}", "revenue")
            self.stats['total_records'] += len(all_totals)
            
            total_paid = sum(t.get('Paid', 0) for t in all_totals)
            logger.info(f"  üí∞ T·ªïng doanh thu: {total_paid:,.0f} VND")
        
        return all_totals
    
    # ==========================================
    # APPOINTMENT SYNC
    # ==========================================
    
    def sync_appointments(self, date_from: str, date_to: str) -> List[Dict]:
        """L·∫•y danh s√°ch l·ªãch h·∫πn"""
        logger.info(f"\nüìÖ ƒêang sync l·ªãch h·∫πn t·ª´ {date_from} ƒë·∫øn {date_to}...")
        
        # Th·ª≠ nhi·ªÅu handler c√≥ th·ªÉ
        handlers_to_try = [
            ("/Appointment/AppointmentInDay/", "LoadData"),
            ("/Appointment/AppointmentInDay/", "Initialize"),
            ("/Appointment/ListAppointment/", "LoadData"),
            ("/Booking/BookingList/", "LoadData"),
        ]
        
        all_appointments = []
        
        for page_url, handler in handlers_to_try:
            result = self.call_handler(
                page_url,
                handler,
                {
                    'dateFrom': f"{date_from} 00:00:00",
                    'dateTo': f"{date_to} 23:59:59",
                    'branchID': 0
                }
            )
            
            if result and isinstance(result, list) and len(result) > 0:
                all_appointments = result
                logger.info(f"  ‚úÖ T√¨m th·∫•y {len(result)} l·ªãch h·∫πn t·ª´ {page_url}")
                break
            elif result and isinstance(result, dict):
                # C√≥ th·ªÉ l√† object ch·ª©a data
                if 'Data' in result:
                    all_appointments = result['Data']
                    logger.info(f"  ‚úÖ T√¨m th·∫•y {len(all_appointments)} l·ªãch h·∫πn t·ª´ {page_url}")
                    break
        
        if all_appointments:
            today = datetime.now().strftime("%Y%m%d")
            self.save_json(all_appointments, f"appointments_{today}", "appointments")
            self.stats['total_records'] += len(all_appointments)
        else:
            logger.info("  ‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu l·ªãch h·∫πn")
        
        return all_appointments
    
    # ==========================================
    # SERVICE DATA SYNC
    # ==========================================
    
    def sync_services_full(self) -> Dict:
        """L·∫•y danh s√°ch d·ªãch v·ª• v·ªõi ƒë·∫ßy ƒë·ªß th√¥ng tin"""
        logger.info("\nüíÖ ƒêang sync d·ªãch v·ª• v·ªõi th√¥ng tin ƒë·∫ßy ƒë·ªß...")
        
        handlers_to_try = [
            ("/Service/ServiceList/", "LoadInit"),
            ("/Service/ServiceList/", "LoadataService"),
            ("/Service/ServiceList/", "Initialize"),
        ]
        
        all_data = {}
        
        for page_url, handler in handlers_to_try:
            result = self.call_handler(page_url, handler, {})
            
            if result:
                if isinstance(result, list):
                    all_data['services'] = result
                    logger.info(f"  ‚úÖ Services t·ª´ {handler}: {len(result)} records")
                elif isinstance(result, dict):
                    all_data.update(result)
                    for key, value in result.items():
                        if isinstance(value, list):
                            logger.info(f"  ‚úÖ {key}: {len(value)} records")
        
        # Th·ª≠ l·∫•y service types
        result = self.call_handler("/Service/ServiceList/", "LoadataServiceType", {})
        if result and isinstance(result, list):
            all_data['service_types'] = result
            logger.info(f"  ‚úÖ Service types: {len(result)} records")
        
        if all_data:
            today = datetime.now().strftime("%Y%m%d")
            self.save_json(all_data, f"services_full_{today}", "services")
            
            total = sum(len(v) for v in all_data.values() if isinstance(v, list))
            self.stats['total_records'] += total
        
        return all_data
    
    # ==========================================
    # EMPLOYEE DATA SYNC
    # ==========================================
    
    def sync_employees_full(self) -> Dict:
        """L·∫•y danh s√°ch nh√¢n vi√™n v·ªõi ƒë·∫ßy ƒë·ªß th√¥ng tin"""
        logger.info("\nüë®‚Äçüíº ƒêang sync nh√¢n vi√™n v·ªõi th√¥ng tin ƒë·∫ßy ƒë·ªß...")
        
        all_data = {}
        
        # L·∫•y employee groups
        result = self.call_handler("/Employee/EmployeeList/", "LoadataEmployeeGroup", {})
        if result and isinstance(result, list):
            all_data['employee_groups'] = result
            logger.info(f"  ‚úÖ Employee groups: {len(result)} records")
        
        # L·∫•y employee list
        result = self.call_handler("/Employee/EmployeeList/", "LoadataEmployee", {})
        if result and isinstance(result, list):
            all_data['employees'] = result
            logger.info(f"  ‚úÖ Employees: {len(result)} records")
        
        if all_data:
            today = datetime.now().strftime("%Y%m%d")
            self.save_json(all_data, f"employees_full_{today}", "employees")
            
            total = sum(len(v) for v in all_data.values() if isinstance(v, list))
            self.stats['total_records'] += total
        
        return all_data
    
    # ==========================================
    # INVENTORY/WAREHOUSE SYNC
    # ==========================================
    
    def sync_inventory(self, date_from: str, date_to: str) -> Dict:
        """L·∫•y d·ªØ li·ªáu kho h√†ng"""
        logger.info(f"\nüì¶ ƒêang sync kho h√†ng t·ª´ {date_from} ƒë·∫øn {date_to}...")
        
        all_data = {}
        
        # Th·ª≠ c√°c endpoint c√≥ th·ªÉ
        pages_to_try = [
            ("/Warehouse/WarehouseList/", ["LoadData", "Initialize", "LoadInit"]),
            ("/Inventory/InventoryList/", ["LoadData", "Initialize"]),
            ("/Stock/StockList/", ["LoadData", "Initialize"]),
            ("/Product/ProductList/", ["LoadData", "Initialize"]),
        ]
        
        for page_url, handlers in pages_to_try:
            for handler in handlers:
                result = self.call_handler(
                    page_url,
                    handler,
                    {
                        'dateFrom': f"{date_from} 00:00:00",
                        'dateTo': f"{date_to} 23:59:59"
                    }
                )
                
                if result:
                    key = f"{page_url.split('/')[1]}_{handler}"
                    all_data[key] = result
                    
                    if isinstance(result, list):
                        logger.info(f"  ‚úÖ {page_url} {handler}: {len(result)} records")
                    elif isinstance(result, dict):
                        logger.info(f"  ‚úÖ {page_url} {handler}: Found data")
        
        if all_data:
            today = datetime.now().strftime("%Y%m%d")
            self.save_json(all_data, f"inventory_{today}", "inventory")
        
        return all_data
    
    # ==========================================
    # TREATMENT DATA SYNC
    # ==========================================
    
    def sync_treatments(self, date_from: str, date_to: str) -> List[Dict]:
        """L·∫•y d·ªØ li·ªáu ƒëi·ªÅu tr·ªã"""
        logger.info(f"\nüíâ ƒêang sync ƒëi·ªÅu tr·ªã t·ª´ {date_from} ƒë·∫øn {date_to}...")
        
        all_data = {}
        
        # Th·ª≠ c√°c endpoint
        pages_to_try = [
            ("/Treatment/TreatmentList/", ["LoadData", "Initialize"]),
            ("/Customer/CustomerTreatment/", ["LoadData", "Initialize"]),
            ("/Procedure/ProcedureList/", ["LoadData", "Initialize"]),
        ]
        
        for page_url, handlers in pages_to_try:
            for handler in handlers:
                result = self.call_handler(
                    page_url,
                    handler,
                    {
                        'dateFrom': f"{date_from} 00:00:00",
                        'dateTo': f"{date_to} 23:59:59",
                        'branchID': 0
                    }
                )
                
                if result:
                    key = f"{page_url.split('/')[1]}_{handler}"
                    all_data[key] = result
                    
                    if isinstance(result, list):
                        logger.info(f"  ‚úÖ {page_url} {handler}: {len(result)} records")
        
        if all_data:
            today = datetime.now().strftime("%Y%m%d")
            self.save_json(all_data, f"treatments_{today}", "treatments")
        
        return all_data
    
    # ==========================================
    # DISCOVER NEW ENDPOINTS
    # ==========================================
    
    def discover_endpoints(self) -> List[Dict]:
        """Kh√°m ph√° c√°c endpoint m·ªõi"""
        logger.info("\nüîç ƒêang kh√°m ph√° endpoints m·ªõi...")
        
        # Danh s√°ch pages c√≥ th·ªÉ c√≥
        potential_pages = [
            "/Customer/ListCustomer/",
            "/Customer/CustomerDetail/",
            "/Customer/CustomerProfile/",
            "/Appointment/AppointmentInDay/",
            "/Appointment/AppointmentList/",
            "/Appointment/ListAppointment/",
            "/Booking/BookingList/",
            "/Booking/BookingCalendar/",
            "/Service/ServiceList/",
            "/Service/ServiceGroup/",
            "/Employee/EmployeeList/",
            "/Employee/EmployeeGroup/",
            "/Staff/StaffList/",
            "/Doctor/DoctorList/",
            "/Revenue/RevenueList/",
            "/Revenue/RevenueReport/",
            "/Payment/PaymentList/",
            "/Report/DailyReport/",
            "/Report/MonthlyReport/",
            "/Report/RevenueReport/",
            "/Dashboard/Index/",
            "/Dashboard/Main/",
            "/Warehouse/WarehouseList/",
            "/Inventory/InventoryList/",
            "/Stock/StockList/",
            "/Product/ProductList/",
            "/Treatment/TreatmentList/",
            "/Procedure/ProcedureList/",
            "/Commission/CommissionList/",
            "/Salary/SalaryList/",
            "/Promotion/PromotionList/",
            "/Voucher/VoucherList/",
            "/Setting/SettingList/",
            "/System/SystemConfig/",
        ]
        
        # Danh s√°ch handlers ph·ªï bi·∫øn
        common_handlers = [
            "Initialize", "LoadInit", "Init",
            "LoadData", "LoadDataAll", "GetList",
            "LoadDataTotal", "GetTotal", "Summary",
            "Search", "Filter", "Query"
        ]
        
        discovered = []
        
        for page in potential_pages:
            for handler in common_handlers:
                result = self.call_handler(page, handler, {})
                
                if result is not None:
                    discovered.append({
                        "page": page,
                        "handler": handler,
                        "type": type(result).__name__,
                        "size": len(result) if isinstance(result, (list, dict)) else 0
                    })
                    logger.info(f"  ‚úÖ Found: {page}?handler={handler}")
                
                time.sleep(0.2)  # Rate limiting
        
        if discovered:
            today = datetime.now().strftime("%Y%m%d")
            self.save_json(discovered, f"discovered_endpoints_{today}", "")
            logger.info(f"  üìã T·ªïng endpoints ph√°t hi·ªán: {len(discovered)}")
        
        return discovered
    
    # ==========================================
    # FULL SYNC
    # ==========================================
    
    def full_sync(self, date_from: str = None, date_to: str = None, 
                  master_only: bool = False, discover: bool = False) -> Dict:
        """Sync to√†n b·ªô d·ªØ li·ªáu"""
        self.stats['start_time'] = datetime.now()
        
        logger.info("=" * 70)
        logger.info("üöÄ VTTech Full Data Sync")
        logger.info(f"   Th·ªùi gian b·∫Øt ƒë·∫ßu: {self.stats['start_time']}")
        logger.info("=" * 70)
        
        results = {}
        
        # 1. ƒêƒÉng nh·∫≠p
        if not self.login():
            return {"error": "Kh√¥ng th·ªÉ ƒëƒÉng nh·∫≠p"}
        
        # 2. Sync Master Data
        results['session_data'] = self.sync_session_data()
        results['branches_full'] = self.sync_branches_full()
        results['services_full'] = self.sync_services_full()
        results['employees_full'] = self.sync_employees_full()
        
        if master_only:
            self._print_summary(results)
            return results
        
        # 3. Setup dates
        if not date_from:
            # M·∫∑c ƒë·ªãnh 30 ng√†y g·∫ßn nh·∫•t
            date_from = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
        if not date_to:
            date_to = datetime.now().strftime("%Y-%m-%d")
        
        logger.info(f"\nüìÖ Kho·∫£ng ng√†y sync: {date_from} ƒë·∫øn {date_to}")
        
        # 4. Sync Daily Data
        results['customer_totals'] = self.sync_customer_totals(date_from, date_to)
        results['customers'] = self.sync_customers(date_from, date_to)
        results['appointments'] = self.sync_appointments(date_from, date_to)
        results['treatments'] = self.sync_treatments(date_from, date_to)
        results['inventory'] = self.sync_inventory(date_from, date_to)
        
        # 5. Discover new endpoints (optional)
        if discover:
            results['discovered'] = self.discover_endpoints()
        
        self._print_summary(results)
        return results
    
    def daily_sync(self, target_date: str = None) -> Dict:
        """Sync d·ªØ li·ªáu h√†ng ng√†y"""
        if not target_date:
            target_date = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
        
        return self.full_sync(date_from=target_date, date_to=target_date)
    
    def _print_summary(self, results: Dict):
        """In t·ªïng k·∫øt"""
        duration = datetime.now() - self.stats['start_time']
        
        logger.info("\n" + "=" * 70)
        logger.info("üìä T·ªîNG K·∫æT SYNC")
        logger.info("=" * 70)
        
        for key, value in results.items():
            if isinstance(value, dict):
                count = sum(v.get('count', 0) if isinstance(v, dict) else len(v) 
                           for v in value.values() if isinstance(v, (dict, list)))
                logger.info(f"  üìÅ {key}: {count} records")
            elif isinstance(value, list):
                logger.info(f"  üìÅ {key}: {len(value)} records")
        
        logger.info(f"\n  üìà T·ªïng records: {self.stats['total_records']:,}")
        logger.info(f"  üîó Endpoints called: {self.stats['endpoints_called']}")
        logger.info(f"  ‚ùå Errors: {self.stats['errors']}")
        logger.info(f"  ‚è±Ô∏è  Th·ªùi gian: {duration}")
        logger.info(f"  üìÇ Output: {SYNC_DIR}")
        
        logger.info("=" * 70)
        logger.info("‚úÖ Ho√†n t·∫•t sync!")
        logger.info("=" * 70)


# ============== MAIN ==============
def main():
    parser = argparse.ArgumentParser(description='VTTech Full Data Sync Crawler')
    parser.add_argument('--master-only', action='store_true', 
                       help='Ch·ªâ sync master data (branches, services, employees)')
    parser.add_argument('--daily', action='store_true',
                       help='Sync d·ªØ li·ªáu h√†ng ng√†y (h√¥m qua)')
    parser.add_argument('--date', type=str,
                       help='Ng√†y c·∫ßn sync (YYYY-MM-DD)')
    parser.add_argument('--date-from', type=str,
                       help='Ng√†y b·∫Øt ƒë·∫ßu (YYYY-MM-DD)')
    parser.add_argument('--date-to', type=str,
                       help='Ng√†y k·∫øt th√∫c (YYYY-MM-DD)')
    parser.add_argument('--discover', action='store_true',
                       help='Kh√°m ph√° endpoints m·ªõi')
    args = parser.parse_args()
    
    crawler = VTTechFullSyncCrawler()
    
    if args.daily:
        crawler.daily_sync(args.date)
    elif args.date:
        crawler.full_sync(date_from=args.date, date_to=args.date)
    else:
        crawler.full_sync(
            date_from=args.date_from,
            date_to=args.date_to,
            master_only=args.master_only,
            discover=args.discover
        )


if __name__ == "__main__":
    main()
